{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVR预估基线版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  基于AD统计的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:10:58.593827Z",
     "start_time": "2020-06-12T03:10:58.590853Z"
    }
   },
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# baseline 1: history pCVR of creativeID/adID/camgaignID/advertiserID/appID/appPlatform\n",
    "# \"\"\"\n",
    "\n",
    "# import zipfile\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # load data\n",
    "# data_root = \".\"\n",
    "# dfTrain = pd.read_csv(\"%s/train.csv\"%data_root)  # 读取当前文件夹（即当前路径./下）下的train.csv文件\n",
    "# dfTest = pd.read_csv(\"%s/test.csv\"%data_root)\n",
    "# dfAd = pd.read_csv(\"s/ad.csv\"%data_root)\n",
    "\n",
    "# # process data\n",
    "# dfTrain = pd.merge(dfTrain,dfAd,on=\"creativeID\")\n",
    "# dfTest = pd.merge(dfTest,dfAd,on=\"creativeID\")\n",
    "# y_train = dfTrain[\"label\"].values\n",
    "\n",
    "# # model building\n",
    "# key = \"appID\"\n",
    "# dfCvr = dfTrain.groupby(key).apply(lambda df: np.mean(df[\"label\"])).reset_index() #根据key计算训练集中label=1的概率\n",
    "# dfCvr.columns = [key,\"avg_cvr\"]\n",
    "# dfTest = pd.merge(dfTest,dfCvr,how=\"left\",on=key)  # 将测试集中含有训练集重合部分的appID的avg_cvr值用训练集中统计的概率值代替\n",
    "# dfTest[\"avg_cvr\"].fillna(np.mean(dfTrain[\"label\"]),inplace=true)  # 将测试集中特有的appID部分的avg_cvr使用训练集所有appID的label=1的概率进行填充\n",
    "# prob_test = dfTest[\"avg_ctr\"].values\n",
    "\n",
    "# # submission\n",
    "# df = pd.DataFrame({\"instanceID\": dfTest[\"instanceID\"].values, \"proba\": proba_test})\n",
    "# df.sort_values(\"instanceID\",inplace=True)\n",
    "# df.to_csv(\"submission.csv\",index=Flase)\n",
    "# with zipfile.ZipFile(\"submission.zip\",\"w\") as fout:\n",
    "#     fout.write(\"submission.csv\",compress_type=zipfile.ZIP_DEFLATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T01:26:08.921583Z",
     "start_time": "2020-06-12T01:26:07.562421Z"
    }
   },
   "source": [
    "### AD+LR版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T04:11:04.003307Z",
     "start_time": "2020-06-12T04:11:03.997327Z"
    }
   },
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# baseline 2: ad.csv (creativeID/adID/camgaignID/advertiserID/appID/appPlatform) + lr\n",
    "# \"\"\"\n",
    "\n",
    "# import zipfile\n",
    "# import pandas as pd \n",
    "# from scipy import sparse\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # load data\n",
    "# data_root = \"./data\"\n",
    "# dfTrain = pd.read_csv(\"%s/train.csv\"%data_root)\n",
    "# dfTest = pd.read_csv(\"%s/test.csv\"%data_root)\n",
    "# dfAd = pd.read_csv(\"%s/ad.csv\"%data_root)\n",
    "\n",
    "# # process data\n",
    "# dfTrain = pd.merge(dfTrain,dfAd,on=\"creativeID\")\n",
    "# dfTest = pd.merge(dfTes,dfAd,on=\"creativeID\")\n",
    "# y_train = dfTrain[\"label\"].values\n",
    "\n",
    "# # feature engineering/encoding\n",
    "# enc = OneHotEncoder()\n",
    "# feats = [\"creativeID\",\"adID\",\"camgaignID\",\"advertiserID\",\"appID\",\"appPlatform\"]\n",
    "# for i,feat in enumerate(feats):\n",
    "#     x_train = enc.fit_transform(dfTrain[feat].values.reshape(-1,1))\n",
    "#     x_test = enc.fit_transform(dfTrain[feat].values.reshape(-1,1))\n",
    "#     if i == 0:\n",
    "#         X_train, X_test = x_train,x_test # 如果是第一个字段的oneHot，则直接赋值给  X_train, X_tes\n",
    "#     else:\n",
    "#         X_trian, X_test = sparse.hstack((X_train,x_train)),sparse.hstack((X_test,x_test)) # 除第一个以后，都将这个与上一个进行横向合并\n",
    "\n",
    "# # model training\n",
    "# lr = LogisticRegression()\n",
    "# lr.fit(X_train,y_trian)\n",
    "# proba_test = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "# # submission\n",
    "# df = pd.DataFrame({\"instanceID\":dfTest[\"instanceID\"],value,\"proba\":proba_test})\n",
    "# df.sort_values(\"instanceID\",index=True)\n",
    "# df.to_csv(\"submission.csv\",index=flase)\n",
    "# with zipfile.ZipFile(\"submission.zip\",\"w\") as fout:\n",
    "#     fout.write(\"submission.csv\",compress_type=zipfile.ZIP_DEFLATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:54:18.933648Z",
     "start_time": "2020-06-12T03:54:18.920689Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
